{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e230b0d",
   "metadata": {},
   "source": [
    "When doing prepare dataset following specs are required\n",
    "* 64 GB Ram\n",
    "* 300 GB Disk Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d072e85",
   "metadata": {},
   "source": [
    "When doing training the recomended specs are:\n",
    "* 24GB GPU RAM\n",
    "* 1 GPU (Nvidia GTX 4090 or better)\n",
    "* 300 GB of free disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4acc9a-0a9e-4eca-8dc1-74d48cd4d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#https://towardsdatascience.com/leveraging-the-power-of-jupyter-notebooks-26b4b8d7c622\n",
    "! jupyter notebook --generate-config\n",
    "! jupyter notebook --NotebookApp.max_buffer_size=258000000000\n",
    "! jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e93d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.env/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.env/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./.env/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in ./.env/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: xxhash in ./.env/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: aiohttp in ./.env/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in ./.env/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: multiprocess in ./.env/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: packaging in ./.env/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.env/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.env/lib/python3.10/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.env/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./.env/lib/python3.10/site-packages (from datasets) (0.23.0.dev0)\n",
      "Requirement already satisfied: pandas in ./.env/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.env/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.env/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.env/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in ./.env/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.env/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.env/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.env/lib/python3.10/site-packages (from transformers) (0.23.0.dev0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.env/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: librosa in ./.env/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: pooch>=1.0 in ./.env/lib/python3.10/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.env/lib/python3.10/site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.env/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.env/lib/python3.10/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./.env/lib/python3.10/site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: joblib>=0.14 in ./.env/lib/python3.10/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.env/lib/python3.10/site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.env/lib/python3.10/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.env/lib/python3.10/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.env/lib/python3.10/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.env/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in ./.env/lib/python3.10/site-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.env/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./.env/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.env/lib/python3.10/site-packages (from pooch>=1.0->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.10/site-packages (from pooch>=1.0->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.env/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.env/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.env/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./.env/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/huggingface/huggingface_hub\n",
      "  Cloning https://github.com/huggingface/huggingface_hub to /tmp/pip-req-build-y3j66f0s\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/huggingface_hub /tmp/pip-req-build-y3j66f0s\n",
      "  Resolved https://github.com/huggingface/huggingface_hub to commit 3abb39735147d2b12413178a9e787acdfec59253\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from huggingface_hub==0.23.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests->huggingface_hub==0.23.0.dev0) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests->huggingface_hub==0.23.0.dev0) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests->huggingface_hub==0.23.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests->huggingface_hub==0.23.0.dev0) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jiwer in ./.env/lib/python3.10/site-packages (3.0.3)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in ./.env/lib/python3.10/site-packages (from jiwer) (3.6.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in ./.env/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "zsh:1: no matches found: transformers[torch]\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in ./.env/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: psutil in ./.env/lib/python3.10/site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.env/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.env/lib/python3.10/site-packages (from accelerate) (0.23.0.dev0)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.env/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: pyyaml in ./.env/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: fsspec in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in ./.env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.env/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in ./.env/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in ./.env/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in ./.env/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.env/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.env/lib/python3.10/site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.env/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: decorator in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: exceptiongroup in ./.env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.env/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.env/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchaudio in ./.env/lib/python3.10/site-packages (2.1.2)\n",
      "Collecting torch==2.1.2\n",
      "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (3.13.1)\n",
      "Collecting triton==2.1.0\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (4.9.0)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: fsspec in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (1.12)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.10/site-packages (from torch==2.1.2->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchaudio) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.env/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchaudio) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nccl-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed nvidia-nccl-cu12-2.18.1 torch-2.1.2 triton-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas \n",
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install librosa\n",
    "%pip install wandb -qU\n",
    "%pip install git+https://github.com/huggingface/huggingface_hub\n",
    "%pip install jiwer\n",
    "%pip install transformers[torch]\n",
    "%pip install accelerate -U\n",
    "%pip install ipywidgets\n",
    "%pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb668a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ac2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "# import re\n",
    "import json\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from transformers import Wav2Vec2Processor\n",
    "import IPython.display as ipd\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9834705f-03b6-43b3-b080-83d0bb13fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "from transformers import Wav2Vec2Processor\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from jiwer import wer\n",
    "import statistics\n",
    "from transformers import Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da3835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tsv’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  274M  100  274M    0     0  11.4M      0  0:00:23  0:00:23 --:--:-- 11.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4226k  100 4226k    0     0  10.7M      0 --:--:-- --:--:-- --:--:-- 10.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1783k  100 1783k    0     0  10.9M      0 --:--:-- --:--:-- --:--:-- 11.0M\n"
     ]
    }
   ],
   "source": [
    "! mkdir tsv\n",
    "! curl https://d38pmlk0v88drf.cloudfront.net/tsv/06_train.tsv --output tsv/train.tsv\n",
    "! curl https://d38pmlk0v88drf.cloudfront.net/tsv/06_val.tsv --output tsv/validation.tsv\n",
    "! curl https://d38pmlk0v88drf.cloudfront.net/tsv/05_benchmark.tsv --output tsv/test.tsv\n",
    "! curl https://d38pmlk0v88drf.cloudfront.net/tsv/vocab.json --output vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab2fa73-08da-482b-885b-5fc9300d022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv(\"tsv/train.tsv\", sep='\\t')\n",
    "dataValid = pd.read_csv(\"tsv/validation.tsv\", sep='\\t')\n",
    "dataTest = pd.read_csv(\"tsv/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb19daf5-a270-4d0a-aa77-a83a8ed781a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696497, 10406, 5366)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataTrain), len(dataValid), len(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcea32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "dataTest['path'] = dataTest['file_name'].apply(lambda x: f'/media/monlamai/SSD/data/wav16k/{x}.wav')\n",
    "\n",
    "dataValid['path'] = dataValid['file_name'].apply(lambda x: f'/media/monlamai/SSD/data/wav16k/{x}.wav')\n",
    "\n",
    "dataTrain['path'] = dataTrain['file_name'].apply(lambda x: f'/media/monlamai/SSD/data/wav16k/{x}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataTest['path'].apply(lambda x: os.path.isfile(x)).value_counts()\n",
    "# dataValid['path'].apply(lambda x: os.path.isfile(x)).value_counts()\n",
    "# batch_df['path'].apply(lambda x: os.path.isfile(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5373f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "common_voice_train = Dataset.from_pandas(dataTrain)\n",
    "common_voice_valid = Dataset.from_pandas(dataValid)\n",
    "common_voice_test = Dataset.from_pandas(dataTest)\n",
    "\n",
    "common_voice_test_transcription = Dataset.from_pandas(dataTest)\n",
    "common_voice_valid_transcription = Dataset.from_pandas(dataValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45f70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceeec2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>uni</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STT_TT00387_707.750-710.750</td>\n",
       "      <td>ག་རེ་བྱེད་དགོས།དེ་ལས་མར་སྤྱི་ཚོགས་སྒང་ལ་མར་འདོན་དགོས་རེད་ཟེར་མྱི་དེ་འདྲའི་ཡེ་ཡོད་རེད།སྣ་ཚོགས་འདུག་གཱ་ད།</td>\n",
       "      <td>/media/monlamai/SSD/data/wav16k/STT_TT00387_707.750-710.750.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STT_NS_M0224_0468_3030622_to_3035861</td>\n",
       "      <td>ཨེ་ནས་ཏོག་ཙི་རྗེས་ལ་བསམ་བློ་ཡག་པོ་ཞིག་བཏང་ཡིན་པ།ཨེ་ནས་འབྲས་འདི་ཡ་ཡུད་ཞིམ་མདོག་ཁ་པོ་མཐོང་སོང་ཡོད་བ།ཨེ་ནས་འགོ་ནས་འཛུལ་ཡིན་པ།</td>\n",
       "      <td>/media/monlamai/SSD/data/wav16k/STT_NS_M0224_0468_3030622_to_3035861.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STT_TT00009_01853.850-01856.150</td>\n",
       "      <td>ནང་གི་རྣམ་པར་ཤེས་པ་དེ་དང་ཆགས་སྡང་གི་བློ་འདི་གས།</td>\n",
       "      <td>/media/monlamai/SSD/data/wav16k/STT_TT00009_01853.850-01856.150.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STT_AB00316_0599_2720230_to_2723336</td>\n",
       "      <td>རང་བཞིན་མེད་པ་ཡང་ཐ་སྙད་པའི་ཚད་མས་མི་འགྲུབ་ལ།</td>\n",
       "      <td>/media/monlamai/SSD/data/wav16k/STT_AB00316_0599_2720230_to_2723336.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STT_CS-X-2018-M-D-B01-1-R-01_0113_817209_to_826911</td>\n",
       "      <td>སྐྱིད་བོ་བྱུང་སོང་ད་རཱ།ཨེ་ནས་རྗེས་ལ་རཱ།ཨེ་ནས་ཡོད་བ་ང་ཚོ་རཱ།ཨེ་ནས་ཡོད་བ་ང་ཚོ་རཱ།ཕར་ཕྱོགས།ཕར་ཕྱོགས།ཕར་ཕྱོགས་རྒྱབ་ལོགས་དེ་ལ།</td>\n",
       "      <td>/media/monlamai/SSD/data/wav16k/STT_CS-X-2018-M-D-B01-1-R-01_0113_817209_to_826911.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(common_voice_train.remove_columns(['dept', 'grade', 'wylie', 'char_len', 'audio_len', 'url']), num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16bc61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"uni\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9defd53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1005cf90fb4f44439bae52c2cbf4bb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/696497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373a2347d00646da9c359f3d7040decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5366 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b8e81bb5f344598bfbf52c2fb5ebbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\n",
    "vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)\n",
    "vocab_valid = common_voice_valid.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_valid.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ac1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(\n",
    "    set(vocab_train[\"vocab\"][0]) | \n",
    "    set(vocab_test [\"vocab\"][0]) | \n",
    "    set(vocab_valid[\"vocab\"][0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15663057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '༌': 1,\n",
       " 'ྔ': 2,\n",
       " '༢': 3,\n",
       " 'ྴ': 4,\n",
       " 'ྀ': 5,\n",
       " 'ྩ': 6,\n",
       " 'ུ': 7,\n",
       " 'ྣ': 8,\n",
       " '༔': 9,\n",
       " 'ྸ': 10,\n",
       " 'ི': 11,\n",
       " 'ཏ': 12,\n",
       " 'ཁ': 13,\n",
       " 'ཱྀ': 14,\n",
       " 'ཎ': 15,\n",
       " 'ྕ': 16,\n",
       " '༣': 17,\n",
       " 'ཐ': 18,\n",
       " 'ག': 19,\n",
       " 'ཥ': 20,\n",
       " 'ཟ': 21,\n",
       " 'ཀྵ': 22,\n",
       " 'ྑ': 23,\n",
       " 'ཤ': 24,\n",
       " '༡': 25,\n",
       " 'ྃ': 26,\n",
       " \"'\": 27,\n",
       " '༧': 28,\n",
       " 'བ': 29,\n",
       " 'ྰ': 30,\n",
       " 'མ': 31,\n",
       " '༩': 32,\n",
       " 'ྵ': 33,\n",
       " '་': 34,\n",
       " 'ེ': 35,\n",
       " 'ལ': 36,\n",
       " '༦': 37,\n",
       " 'ཷ': 38,\n",
       " 'ྦ': 39,\n",
       " 'ཚ': 40,\n",
       " 'ྠ': 41,\n",
       " 'ྗ': 42,\n",
       " 'ཛ': 43,\n",
       " 'ཱི': 44,\n",
       " '།': 45,\n",
       " 'ྞ': 46,\n",
       " 'ཀ': 47,\n",
       " 'ཻ': 48,\n",
       " 'ཇ': 49,\n",
       " 'ྐ': 50,\n",
       " 'འ': 51,\n",
       " '྇': 52,\n",
       " 'ྤ': 53,\n",
       " 'ྜ': 54,\n",
       " 'ཪ': 55,\n",
       " 'ྡྷ': 56,\n",
       " '༨': 57,\n",
       " 'ྒ': 58,\n",
       " 'ས': 59,\n",
       " 'ྻ': 60,\n",
       " 'ཅ': 61,\n",
       " 'ར': 62,\n",
       " 'ོ': 63,\n",
       " 'ༀ': 64,\n",
       " 'ྶ': 65,\n",
       " 'ཕ': 66,\n",
       " 'ྪ': 67,\n",
       " 'ད': 68,\n",
       " 'ཝ': 69,\n",
       " 'ཞ': 70,\n",
       " 'ྖ': 71,\n",
       " 'ཉ': 72,\n",
       " 'ཌྷ': 73,\n",
       " '\\u1ae5': 74,\n",
       " 'ཆ': 75,\n",
       " '༥': 76,\n",
       " 'ྂ': 77,\n",
       " 'ཱ': 78,\n",
       " 'དྷ': 79,\n",
       " 'ྲ': 80,\n",
       " 'ང': 81,\n",
       " 'ྚ': 82,\n",
       " 'ཋ': 83,\n",
       " 'ྨ': 84,\n",
       " 'ྼ': 85,\n",
       " 'ྙ': 86,\n",
       " 'ྥ': 87,\n",
       " '༤': 88,\n",
       " 'ྟ': 89,\n",
       " 'ཿ': 90,\n",
       " 'ཌ': 91,\n",
       " 'ཾ': 92,\n",
       " 'ླ': 93,\n",
       " 'པ': 94,\n",
       " '༸': 95,\n",
       " 'བྷ': 96,\n",
       " 'ྷ': 97,\n",
       " 'ཽ': 98,\n",
       " 'ྱ': 99,\n",
       " 'ྡ': 100,\n",
       " 'ན': 101,\n",
       " 'ཨ': 102,\n",
       " 'ཙ': 103,\n",
       " 'ྫ': 104,\n",
       " 'ྦྷ': 105,\n",
       " 'གྷ': 106,\n",
       " 'ཡ': 107,\n",
       " 'ཱུ': 108,\n",
       " 'ྭ': 109,\n",
       " 'ཧ': 110,\n",
       " 'ཊ': 111,\n",
       " 'ྛ': 112}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57c17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a97a97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffa746b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "Transformers version: 4.36.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4550bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.env/lib/python3.10/site-packages (2.1.2)\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.env/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.env/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in ./.env/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.env/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.env/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.env/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: fsspec in ./.env/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.env/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting triton==2.2.0\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.env/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nccl-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.2 requires torch==2.1.2, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.19.3 torch-2.2.2 triton-2.2.0\n",
      "Requirement already satisfied: transformers in ./.env/lib/python3.10/site-packages (4.36.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.env/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.env/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.env/lib/python3.10/site-packages (from transformers) (0.23.0.dev0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.env/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "Successfully installed transformers-4.39.3\n"
     ]
    }
   ],
   "source": [
    "%pip install torch --upgrade\n",
    "%pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37caac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "Transformers version: 4.36.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaed1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('vocab.json', 'w') as vocab_file:\n",
    "#     json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3b21a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./vocab.json to s3://monlam.ai.stt/tsv/vocab.json     \n"
     ]
    }
   ],
   "source": [
    "# ! aws s3 cp vocab.json s3://monlam.ai.stt/tsv/vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87386108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4191830",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(\"wav2vec2_run10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    # print(batch)\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    # print(speech_array.shape, sampling_rate)\n",
    "    if sampling_rate != 16000:\n",
    "        print(\"resampling\")\n",
    "        resampler = Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        speech_array = resampler(speech_array)\n",
    "        sampling_rate = 16000\n",
    "    \n",
    "    # print(speech_array.shape, sampling_rate)\n",
    "    batch[\"speech\"] = speech_array[0].numpy()\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"uni\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train = common_voice_train.map(speech_file_to_array_fn, remove_columns=common_voice_train.column_names)\n",
    "common_voice_train.save_to_disk(f\"/media/monlamai/SSD/wav2vec2/train_speech_file_to_array_fn.arrow\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names)\n",
    "common_voice_test.save_to_disk(   \"/media/monlamai/SSD/wav2vec2/test_speech_file_to_array_fn.arrow\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7530260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_voice_valid = common_voice_valid.map(speech_file_to_array_fn, remove_columns=common_voice_valid.column_names)\n",
    "common_voice_valid.save_to_disk(   \"/media/monlamai/SSD/wav2vec2/valid_speech_file_to_array_fn.arrow\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938dd8e-09e8-4cd6-83e8-110b09d4dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "# common_voice_train = load_from_disk(f'/media/monlamai/SSD/wav2vec2/train_speech_file_to_array_fn.arrow')\n",
    "# common_voice_test = load_from_disk('/media/monlamai/SSD/wav2vec2/test_speech_file_to_array_fn.arrow')\n",
    "# common_voice_valid = load_from_disk('/media/monlamai/SSD/wav2vec2/valid_speech_file_to_array_fn.arrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198081c",
   "metadata": {},
   "source": [
    "humm. This does not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(common_voice_test)-1)\n",
    "\n",
    "ipd.Audio(data=np.asarray(common_voice_test[rand_int][\"path\"]), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_int = random.randint(0, len(common_voice_test)-1)\n",
    "\n",
    "print(\"Target text:\", common_voice_train[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(common_voice_train[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", common_voice_train[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"]).input_values\n",
    "    # reshape to (n,)\n",
    "    batch[\"input_values\"] = np.squeeze(batch[\"input_values\"])\n",
    "    # if batch[\"sampling_rate\"] != 16000:\n",
    "    #     print(\"sampling rate not 16k\", batch)\n",
    "    \n",
    "    # with processor.as_target_processor():\n",
    "    #     batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "\n",
    "    batch[\"labels\"] = processor(text=batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_dataset(batch):\n",
    "#     # check that all files have the correct sampling rate\n",
    "#     assert (\n",
    "#         len(set(batch[\"sampling_rate\"])) == 1\n",
    "#     ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "#     batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "\n",
    "#     with processor.as_target_processor():\n",
    "#         batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "#     return batch\n",
    "\n",
    "# common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names, batch_size=4, num_proc=2, batched=True)\n",
    "# common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names, batch_size=8, num_proc=4, batched=True)\n",
    "# common_voice_valid = common_voice_valid.map(prepare_dataset, remove_columns=common_voice_valid.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names)\n",
    "common_voice_train.save_to_disk(f\"/media/monlamai/SSD/wav2vec2/train_prepare_dataset.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names)\n",
    "common_voice_test.save_to_disk(\"/media/monlamai/SSD/wav2vec2/test_prepare_dataset.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30841c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_voice_valid = common_voice_valid.map(prepare_dataset, remove_columns=common_voice_valid.column_names)\n",
    "common_voice_valid.save_to_disk(\"/media/monlamai/SSD/wav2vec2/valid_prepare_dataset.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770edb87-ad61-4e38-b5b6-48f8c2539aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict\n",
    "# ddict = DatasetDict({\n",
    "#     \"train\": common_voice_train,\n",
    "#     \"valid\": common_voice_valid,\n",
    "#     \"test\": common_voice_test,\n",
    "# })\n",
    "# ddict.push_to_hub(\"prepare_dataset_run8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c8e11",
   "metadata": {},
   "source": [
    "### Load the datasets from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756606dc-4bca-434e-98fd-fc69d1035f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "common_voice_train = load_from_disk('/media/monlamai/SSD/wav2vec2/train_prepare_dataset.arrow')\n",
    "common_voice_test = load_from_disk( '/media/monlamai/SSD/wav2vec2/test_prepare_dataset.arrow')\n",
    "common_voice_valid = load_from_disk('/media/monlamai/SSD/wav2vec2/valid_prepare_dataset.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a2c03-1fdd-4f3b-8321-f21824aa16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740da37-af05-4294-a015-3bd631e2af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111412b-9d0b-4529-b67f-a7fc747b2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4368847-2256-4b66-a4d7-8c9a7b75718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8edf07-1f8c-4fb5-b01b-fb09aafa9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", # commented for for continue training\n",
    "    # \"/media/monlamai/SSD/wav2vec2/wav2vec2_run9/checkpoint-80000\", # inserted for continue training\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, # If True, use gradient checkpointing to save memory at the expense of slower backward pass.\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id, # commented for for continue training\n",
    "    vocab_size=len(processor.tokenizer), # commented for for continue training\n",
    "    # ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2642e-324c-46a8-bb30-6bb8bb4d0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a07af5-c328-4fcc-8e4e-215fb3080af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.ctc_zero_infinity = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33e6f7-6095-4a5a-a12f-333ce2b9f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"/media/monlamai/SSD/wav2vec2/wav2vec2_run10\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=16,\n",
    "  gradient_accumulation_steps=1, # increase by 2x for every 2x decrease in batch size\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=25,\n",
    "  fp16=True,\n",
    "  save_steps=5000,\n",
    "  eval_steps=5000,\n",
    "  logging_steps=100,\n",
    "  report_to=['tensorboard'],\n",
    "  learning_rate=3e-5,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=6,\n",
    "  push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd236f00-b36d-46c3-a631-f2507040651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_valid,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99095de-fbb0-4732-8c67-3a327dee59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_from_checkpoint=True # commented for for continue training\n",
    "# trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d783630-2fb6-43ea-8bbe-07a8885f59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"wav2vec2_run8/\").to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2_run8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a426cd-511e-4c77-a636-f4f2da728fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = processor(common_voice_test[0][\"input_values\"], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "logits = model(input_dict.input_values.to(\"cuda\")).logits\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd7788-3073-4027-945e-9ec13741f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction:\")\n",
    "print(processor.decode(pred_ids))\n",
    "\n",
    "print(\"\\nReference:\")\n",
    "print(common_voice_test_transcription[0][\"sentence\"].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15655ee7-e01f-4fd3-8b03-6fbe896a9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "reference = []\n",
    "paths = []\n",
    "\n",
    "for i in range(0,len(common_voice_test)):\n",
    "\n",
    "  input_dict = processor(common_voice_test[i][\"input_values\"], return_tensors=\"pt\", padding=True)\n",
    "  logits = model(input_dict.input_values.to(\"cuda\")).logits\n",
    "  pred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "  #print(\"Prediction:\")\n",
    "  prediction.append(processor.decode(pred_ids))\n",
    "\n",
    "  #print(\"\\nReference:\")\n",
    "  reference.append(common_voice_test_transcription[i][\"sentence\"].lower())\n",
    "\n",
    "  path = common_voice_test_transcription[i][\"path\"]\n",
    "  path = path.split(\"/\")\n",
    "  path = path[-1]\n",
    "  paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c354322-b869-46dc-812b-9cab7637de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(reference)):\n",
    "  print(paths[i])\n",
    "  print(reference[i])\n",
    "  print(prediction[i])\n",
    "  print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b26b26-93c2-416f-92eb-c5c71e4a91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This are necessary for the statistics reporting\n",
    "from google.colab import files\n",
    "import re\n",
    "from jiwer import wer\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c77eff-2065-43d7-ac9a-304c9abf720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Levenshtein Distance between two strings (character distance)\n",
    "# https://colab.research.google.com/github/Alexjmsherman/nlp_practicum_cohort3_instructor/blob/master/lessons/lesson_8_text_similarity/text_similarity_solution.ipynb#scrollTo=sSj3zYpq-sc1\n",
    "\n",
    "def levenshtein(seq1, seq2):\n",
    "    # create a matrix\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "\n",
    "    # set col numbers (0, n-1)\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "\n",
    "    # set row numbers (0, n-1)\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    # calculate distance\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            # if characters match do not increase distance\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = matrix[x-1, y-1]\n",
    "            # if characters don't match increase min distance by 1\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c83f76-f498-47ed-a97c-a8908daad63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Evaluate checkpoints; calculate their word/character error rates and\n",
    "# get the predictions for the sentences in the test set.\n",
    "#===============================================================================\n",
    "\n",
    "checkpointNums = [\"2900\"]\n",
    "\n",
    "medianStats = \"\"\n",
    "\n",
    "for ch in checkpointNums:\n",
    "\n",
    "\tcheckpointNum = ch\n",
    "\n",
    "\tfilename = \"wav2vec2-res-\" + str(runId) + \"-ch\" + ch + \".csv\"\n",
    "\tidThisRun = \"wav2vec2-\" + str(runId)\n",
    "\n",
    "\t# model = Wav2Vec2ForCTC.from_pretrained(\"/content/wav2vec2-large-xlsr/checkpoint-\"+ch).to(\"cuda\")\n",
    "\t# processor = Wav2Vec2Processor.from_pretrained(\"/content/wav2vec2-large-xlsr\")\n",
    "\n",
    "\tinput_dict = processor(common_voice_test[0][\"input_values\"], return_tensors=\"pt\", padding=True)\n",
    "\tlogits = model(input_dict.input_values.to(\"cuda\")).logits\n",
    "\tpred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "\tprediction = []\n",
    "\treference = []\n",
    "\tpaths = []\n",
    "\n",
    "\tfor i in range(0,len(common_voice_test)):\n",
    "\n",
    "\t\tinput_dict = processor(common_voice_test[i][\"input_values\"], return_tensors=\"pt\", padding=True)\n",
    "\t\tlogits = model(input_dict.input_values.to(\"cuda\")).logits\n",
    "\t\tpred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "\t\t#print(\"Prediction:\")\n",
    "\t\tprediction.append(processor.decode(pred_ids))\n",
    "\n",
    "\t\t#print(\"\\nReference:\")\n",
    "\t\treference.append(common_voice_test_transcription[i][\"sentence\"].lower())\n",
    "\n",
    "\t\tpath = common_voice_test_transcription[i][\"path\"]\n",
    "\t\tpath = path.split(\"/\")\n",
    "\t\tpath = path[-1]\n",
    "\t\tpaths.append(path)\n",
    "\n",
    "\toutput = \"wav,src,res,loss,charDist,charLen,wordDist,wordLen,cer,wer,origin,condition,id,typeMonoTri,ngram\\n\"\n",
    "\tcerList = []\n",
    "\twerList = []\n",
    "\n",
    "\tfor i in range(0,len(reference)):\n",
    "\n",
    "\t\tlevDistChar = levenshtein(reference[i],prediction[i])\n",
    "\t\tcer = levDistChar / len(reference[i])\n",
    "\n",
    "\t\twerSent = wer(reference[i],prediction[i])\n",
    "\t\tcharLen = len(reference[i])\n",
    "\t\tcharDist = levDistChar\n",
    "\t\twordLen = len(prediction[i].split(' '))\n",
    "\t\twordDist = werSent*wordLen\n",
    "\n",
    "\t\tcerList.append(cer)\n",
    "\t\twerList.append(werSent)\n",
    "\n",
    "\t\twavFile = paths[i].replace(\".wav\",\"\")\n",
    "\n",
    "\t\toutput += wavFile + \",\" + reference[i] + \",\" + prediction[i] + \",,\" + str(charDist) + \",\" + str(charLen) + \",\" + str(wordDist) + \",\" + str(wordLen) + \",\" + str(round(cer,2)) + \",\" + str(round(werSent,2)) + \",\" + \"wav2vec2\" + \",\" + \"standard-\" + ch + \",\" + str(idThisRun) + \",\" + \"na\" + \",\" + \"na\" + \"\\n\"\n",
    "\n",
    "\toutput = output[:-1]\n",
    "\t#print(output)\n",
    "\n",
    "\tcerMedian = statistics.median(cerList)\n",
    "\twerMedian = statistics.median(werList)\n",
    "\n",
    "\tmedianStats += runId + \"/\" + ch + \" Median CER:\\t\" + str(round(cerMedian,3)) + \"\\n\"\n",
    "\tmedianStats += runId + \"/\" + ch + \" Median WER:\\t\" + str(round(werMedian,3)) + \"\\n\\n\"\n",
    "\n",
    "\t#print(runId + \"/\" + ch + \" Median CER:\\t\" + str(round(cerMedian,3)))\n",
    "\t#print(runId + \"/\" + ch + \" Median WER:\\t\" + str(round(werMedian,3)))\n",
    "\n",
    "\tprint(output)\n",
    "\n",
    "print(medianStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acafe01-bb7b-477f-93a5-7eddf9b4a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "medianStats = \"Run: \" + runId + \"\\n\\n\" + medianStats\n",
    "\n",
    "statsFilename = \"wav2vec2-res-\"+str(runId)+\"-stats-median.txt\"\n",
    "f = open(datasetPath + \"logs-wav2vec2-res/\" + statsFilename, \"w\")\n",
    "f.write(medianStats)\n",
    "f.close()\n",
    "\n",
    "print(medianStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357f985-cb31-494f-9f01-85ec174abc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of CER and WER\n",
    "df = pd.read_csv(datasetPath + \"logs-wav2vec2-res/\" + filename)\n",
    "df.boxplot(by =['origin'], column =['cer','wer'], grid = False)\n",
    "\n",
    "# For quick visualization only (display only sentences with CER and WER less than 2)\n",
    "dfOnlyLessThanTwo = df[df['cer']<2]\n",
    "dfOnlyLessThanTwo = dfOnlyLessThanTwo[dfOnlyLessThanTwo['wer']<2]\n",
    "dfOnlyLessThanTwo.boxplot(by =['origin'], column =['cer','wer'], grid = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
